{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_cars_path = \"C:\\\\Users\\\\Sasha\\\\Desktop\\\\broken cars\\\\datasets\\\\good_cars\"\n",
    "damaged_cars_path = \"C:\\\\Users\\\\Sasha\\\\Desktop\\\\broken cars\\\\datasets\\\\damaged_cars\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of good cars: 3995\n",
      "Number of damaged cars: 4148\n"
     ]
    }
   ],
   "source": [
    "good_cars = glob.glob(good_cars_path+\"\\\\*.jpg\")\n",
    "damaged_cars = glob.glob(damaged_cars_path+\"\\\\*.jpg\")\n",
    "\n",
    "print(\"Number of good cars:\", len(good_cars))\n",
    "print(\"Number of damaged cars:\", len(damaged_cars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cars = good_cars + damaged_cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the data into train, validation and test datasets: 80%; 10%; 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_cars.sort()\n",
    "random.shuffle(all_cars)\n",
    "\n",
    "all_labels = []\n",
    "for car in all_cars:\n",
    "    if \"good\" in car:\n",
    "        all_labels.append(0)\n",
    "    else:\n",
    "        all_labels.append(1)\n",
    "\n",
    "split_1 = int(0.8 * len(all_cars))\n",
    "split_2 = int(0.9 * len(all_cars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_cars = all_cars[:split_1]\n",
    "valid_cars = all_cars[split_1:split_2]\n",
    "test_cars = all_cars[split_2:]\n",
    "\n",
    "train_cars_labels = all_labels[:split_1]\n",
    "valid_cars_labels = all_labels[split_1:split_2]\n",
    "test_cars_labels = all_labels[split_2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the ratio of good and damaged cars across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9644149577804584\n",
      "Validation: 0.9334916864608076\n",
      "Test: 0.9829683698296837\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", (len(train_cars_labels) - sum(train_cars_labels))/float(sum(train_cars_labels)))\n",
    "print(\"Validation:\", (len(valid_cars_labels) - sum(valid_cars_labels))/float(sum(valid_cars_labels)))\n",
    "print(\"Test:\", (len(test_cars_labels) - sum(test_cars_labels))/float(sum(test_cars_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the ratios are close, which is a good thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"train.p\", \"wb\") as train_pickle:\n",
    "    pickle.dump((train_cars, train_cars_labels), train_pickle) \n",
    "with open(\"valid.p\", \"wb\") as train_pickle:\n",
    "    pickle.dump((valid_cars, valid_cars_labels), train_pickle) \n",
    "with open(\"test.p\", \"wb\") as train_pickle:\n",
    "    pickle.dump((test_cars, test_cars_labels), train_pickle) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the final dataset sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 6514\n",
      "Validation: 814\n",
      "Test: 815\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", len(train_cars))\n",
    "print(\"Validation:\", len(valid_cars))\n",
    "print(\"Test:\", len(test_cars))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_captioning",
   "language": "python",
   "name": "image_captioning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
